# Implementation Plan: RAG Chatbot

**Branch**: `002-rag-chatbot` | **Date**: 2025-12-17 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-rag-chatbot/spec.md`

## Summary

Build an integrated RAG chatbot for the Physical AI & Humanoid Robotics book using:
- **FastAPI** backend with OpenAI Python SDK for agent/chat logic
- **Cohere** embedding model
- **Qdrant** vector database for semantic search
- **Neon Postgres** for metadata storage
- **Docusaurus** frontend with embedded chat UI

The chatbot answers questions exclusively from book content, with source attribution and graceful out-of-scope handling.

## Technical Context

**Language/Version**: Python 3.11+
**Primary Dependencies**: FastAPI, OpenAI SDK, qdrant-client, asyncpg, pydantic
**Storage**: Qdrant (vectors), Neon Postgres (metadata)
**Testing**: pytest, pytest-asyncio, httpx (contract tests)
**Target Platform**: Linux server (Docker), Docusaurus static site
**Project Type**: Web application (backend + frontend integration)
**Performance Goals**: <3s query latency, 100 concurrent users
**Constraints**: <100ms vector search, 99% availability
**Scale/Scope**: 50+ chapters, ~3000 chunks, 1000+ daily queries

## Constitution Check

*GATE: Must pass before implementation. All items verified.*

| Principle | Status | Implementation |
|-----------|--------|----------------|
| Spec-First Development | âœ… Pass | Spec completed and clarified |
| Clarity & Consistency | âœ… Pass | API contracts defined, data model documented |
| Accuracy Over Speed | âœ… Pass | Grounding check before response generation |
| Iterative Improvement | âœ… Pass | Re-ingestion CLI for content updates |
| Transparency & Grounding | âœ… Pass | Out-of-scope fallback message defined |
| RAG-Grounded Responses | âœ… Pass | Relevance threshold (0.7), source attribution |
| SDK-First Architecture | âœ… Pass | OpenAI Python SDK for all LLM interactions |

## Project Structure

### Documentation (this feature)

```text
specs/002-rag-chatbot/
â”œâ”€â”€ spec.md              # Feature specification
â”œâ”€â”€ plan.md              # This file
â”œâ”€â”€ research.md          # Technical research findings
â”œâ”€â”€ data-model.md        # Database schema and entities
â”œâ”€â”€ quickstart.md        # Developer setup guide
â”œâ”€â”€ contracts/
â”‚   â””â”€â”€ api-contracts.md # REST API definitions
â””â”€â”€ tasks.md             # Implementation tasks (via /sp.tasks)
```

### Source Code (repository root)

```text
Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry
â”‚   â”œâ”€â”€ config.py            # Environment configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ requests.py      # Pydantic request models
â”‚   â”‚   â”œâ”€â”€ responses.py     # Pydantic response models
â”‚   â”‚   â””â”€â”€ entities.py      # Domain entities (BookChunk, etc.)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding.py     # Cohere embedding service
â”‚   â”‚   â”œâ”€â”€ retrieval.py     # Qdrant search service
â”‚   â”‚   â”œâ”€â”€ generation.py    # OpenAI response generation
â”‚   â”‚   â””â”€â”€ ingestion.py     # Content ingestion pipeline
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py        # API route definitions
â”‚   â”‚   â”œâ”€â”€ query.py         # /query endpoint handler
â”‚   â”‚   â”œâ”€â”€ ingest.py        # /ingest endpoint handler
â”‚   â”‚   â”œâ”€â”€ health.py        # /health endpoint handler
â”‚   â”‚   â””â”€â”€ metrics.py       # /metrics endpoint handler
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ postgres.py      # Asyncpg connection pool
â”‚   â”‚   â”œâ”€â”€ qdrant.py        # Qdrant client wrapper
â”‚   â”‚   â””â”€â”€ migrations/      # Alembic migrations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ chunking.py      # Markdown chunking logic
â”‚       â”œâ”€â”€ sanitizer.py     # Input sanitization
â”‚       â””â”€â”€ logging.py       # Structured logging
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ingest.py            # CLI for manual ingestion
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Pytest fixtures
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_chunking.py
â”‚   â”‚   â”œâ”€â”€ test_embedding.py
â”‚   â”‚   â””â”€â”€ test_sanitizer.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_retrieval.py
â”‚   â”‚   â”œâ”€â”€ test_ingestion.py
â”‚   â”‚   â””â”€â”€ test_generation.py
â”‚   â””â”€â”€ contract/
â”‚       â”œâ”€â”€ test_query_api.py
â”‚       â”œâ”€â”€ test_ingest_api.py
â”‚       â””â”€â”€ test_health_api.py
â”œâ”€â”€ pyproject.toml           # Project dependencies
â”œâ”€â”€ Dockerfile               # Container build
â”œâ”€â”€ docker-compose.yml       # Local development stack
â””â”€â”€ .env.example             # Environment template

src/components/
â””â”€â”€ ChatWidget/
    â”œâ”€â”€ index.tsx            # Chat widget component
    â”œâ”€â”€ ChatWidget.module.css
    â””â”€â”€ types.ts             # TypeScript interfaces

static/
â””â”€â”€ js/
    â””â”€â”€ chat-embed.js        # Standalone embed script
```

**Structure Decision**: Web application structure with separated Backend (FastAPI) and Frontend integration (Docusaurus components). Backend follows clean architecture with distinct layers: API â†’ Services â†’ Database.

## Architecture Overview

### System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           DOCUSAURUS SITE                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        Chat Widget (React)                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Input    â”‚â”€â”€â”€â–¶â”‚  Submit   â”‚â”€â”€â”€â–¶â”‚  Display Response     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Field    â”‚    â”‚  Button   â”‚    â”‚  + Sources            â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                         â”‚                                       â”‚   â”‚
â”‚  â”‚                         â”‚ HTTP POST /query                      â”‚   â”‚
â”‚  â”‚                         â–¼                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FASTAPI BACKEND                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        API Layer                                 â”‚   â”‚
â”‚  â”‚  /query    /ingest    /health    /metrics                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Service Layer                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚  â”‚Embedding â”‚   â”‚Retrieval â”‚   â”‚Generationâ”‚   â”‚Ingestion â”‚     â”‚   â”‚
â”‚  â”‚  â”‚ Service  â”‚   â”‚ Service  â”‚   â”‚ Service  â”‚   â”‚ Service  â”‚     â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚              â”‚              â”‚              â”‚                 â”‚
â”‚          â–¼              â–¼              â–¼              â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚                 â”‚
â”‚  â”‚ Cohere        â”‚ â”‚  Qdrant   â”‚ â”‚  OpenAI   â”‚      â”‚                 â”‚
â”‚  â”‚ (Embeddings)  â”‚ â”‚ (Vectors) â”‚ â”‚  (LLM)    â”‚      â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                 â”‚
â”‚                           â”‚                          â”‚                 â”‚
â”‚                           â–¼                          â”‚                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚                 â”‚
â”‚                    â”‚   Neon    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                    â”‚ Postgres  â”‚                                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sequence Diagrams

#### Query Flow

```
User        ChatWidget      FastAPI       EmbeddingSvc    Qdrant      OpenAI
 â”‚              â”‚              â”‚              â”‚             â”‚            â”‚
 â”‚â”€ Ask Q â”€â”€â”€â”€â”€â–¶â”‚              â”‚              â”‚             â”‚            â”‚
 â”‚              â”‚â”€ POST /queryâ–¶â”‚              â”‚             â”‚            â”‚
 â”‚              â”‚              â”‚â”€ embed(Q) â”€â”€â–¶â”‚             â”‚            â”‚
 â”‚              â”‚              â”‚â—€â”€ vector â”€â”€â”€â”€â”‚             â”‚            â”‚
 â”‚              â”‚              â”‚â”€ search(vec)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚          â”‚
 â”‚              â”‚              â”‚â—€â”€ top 5 chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚          â”‚
 â”‚              â”‚              â”‚                              â”‚            â”‚
 â”‚              â”‚              â”‚â”€â”€ Check relevance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚              â”‚              â”‚   (score â‰¥ 0.7?)             â”‚            â”‚
 â”‚              â”‚              â”‚                              â”‚            â”‚
 â”‚              â”‚              â”‚â”€ generate(context + Q) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
 â”‚              â”‚              â”‚â—€â”€ stream tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 â”‚              â”‚â—€â”€ SSE tokensâ”€â”‚              â”‚             â”‚            â”‚
 â”‚â—€â”€ Display â”€â”€â”€â”‚              â”‚              â”‚             â”‚            â”‚
 â”‚              â”‚              â”‚              â”‚             â”‚            â”‚
```

#### Ingestion Flow

```
Admin       CLI         FastAPI      ChunkingSvc    EmbeddingSvc    Qdrant    Postgres
  â”‚          â”‚             â”‚              â”‚              â”‚            â”‚           â”‚
  â”‚â”€ ingest â–¶â”‚             â”‚              â”‚              â”‚            â”‚           â”‚
  â”‚          â”‚â”€POST /ingestâ–¶â”‚             â”‚              â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚â”€ scan files â–¶â”‚              â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚â—€â”€ file list â”€â”‚              â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚              â”‚              â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚â”€â”€ For each file: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
  â”‚          â”‚             â”‚   â”‚                         â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚â”€ chunk(content) â”€â”€â”€â”€â”€â”€â”€â–¶â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚â—€â”€ chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚                         â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚â”€ embed(chunk) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚           â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚â—€â”€ vector â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚                         â”‚            â”‚           â”‚
  â”‚          â”‚             â”‚   â”‚â”€ upsert(vector) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚          â”‚
  â”‚          â”‚             â”‚   â”‚â”€ upsert(metadata) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚
  â”‚          â”‚             â”‚   â”‚                         â”‚            â”‚           â”‚
  â”‚          â”‚â—€â”€ 202 â”€â”€â”€â”€â”€â”€â”‚â—€â”€â”€â”˜                         â”‚            â”‚           â”‚
  â”‚â—€â”€ done â”€â”€â”‚             â”‚              â”‚              â”‚            â”‚           â”‚
```

## Technical Decisions

### 1. Embedding Strategy

**Decision**: Use Cohere for embeddings.

**Implementation**:
```python
import cohere
from app.models.entities import EmbeddingResult

class EmbeddingService:
    def __init__(self, api_key: str, model: str = "embed-english-v3.0"):
        self._client = cohere.AsyncClient(api_key)
        self._model = model

    async def embed(self, text: str) -> EmbeddingResult:
        response = await self._client.embed(
            texts=[text],
            model=self._model,
            input_type="search_document"
        )
        return EmbeddingResult(
            vector=response.embeddings[0],
            model_used="cohere",
            latency_ms=...
        )
```

**Rationale**: Simplifies the architecture by using a single, high-quality embedding service.

### 2. Streaming Responses

**Decision**: Enable SSE streaming by default for `/query`

**Implementation**: FastAPI StreamingResponse with async generator

**Rationale**: Reduces perceived latency; first token visible in <500ms vs 2-3s for full response.

### 3. Chunking Parameters

**Decision**: 512 tokens with 50-token overlap

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| Chunk size | ~512 tokens (~2000 chars) | Fits context window, semantically coherent |
| Overlap | ~50 tokens (~200 chars) | Prevents boundary context loss |
| Splitter | Markdown-aware recursive | Respects document structure |

### 4. Relevance Threshold

**Decision**: 0.7 cosine similarity for "confident" responses

| Score Range | Confidence | Behavior |
|-------------|------------|----------|
| â‰¥ 0.8 | High | Full answer with sources |
| 0.7 - 0.8 | Medium | Answer with uncertainty note |
| < 0.7 | Low | Fallback: "I don't know based on the book content" |

### 5. Rate Limiting Strategy

**Decision**: Queue with feedback (per spec clarification)

**Implementation**:
- In-memory queue (asyncio.Queue) for MVP
- Max queue depth: 50 requests
- Display queue position to user
- Timeout: 30 seconds

### 6. Session Management

**Decision**: Browser sessionStorage only (no server-side persistence)

**Rationale**: Simplifies architecture; out-of-scope for MVP per spec.

## API Endpoints Summary

| Endpoint | Method | Auth | Purpose |
|----------|--------|------|---------|
| `/v1/query` | POST | None | Submit question, get answer |
| `/v1/ingest` | POST | API Key | Trigger content ingestion |
| `/v1/ingest/{run_id}` | GET | API Key | Check ingestion progress |
| `/v1/health` | GET | None | System health check |
| `/v1/metrics` | GET | API Key | Performance metrics |

Full contracts: [contracts/api-contracts.md](./contracts/api-contracts.md)

## Data Model Summary

### Qdrant Collection: `book_chunks`

- Vector size: 1024 dimensions
- Distance: Cosine
- Payload: chunk_id, content, chapter, section, position

### Postgres Tables

| Table | Purpose |
|-------|---------|
| `chunk_metadata` | Links vector IDs to source files |
| `ingestion_runs` | Tracks ingestion history |
| `retrieval_logs` | Query audit trail |
| `system_metrics` | Rolling performance data |

Full schema: [data-model.md](./data-model.md)

## Testing Strategy

### Test Categories

| Category | Scope | Tools |
|----------|-------|-------|
| Unit | Individual functions | pytest |
| Integration | Service interactions | pytest-asyncio, testcontainers |
| Contract | API compliance | httpx, pytest |
| Load | Performance targets | locust |
| Security | Injection, auth | manual + automated |

### Key Test Cases

1. **Retrieval Accuracy**: Known questions return expected chunks (â‰¥80% precision)
2. **Grounding Compliance**: Out-of-scope queries return fallback (100%)
3. **Latency**: End-to-end <3s under normal load
4. **Concurrent Users**: 100 simultaneous queries without degradation
5. **Input Sanitization**: Script injection is neutralized

### Test Data

- Sample book content: 10 chapters for integration tests
- Known Q&A pairs: 50 curated for accuracy testing
- Out-of-scope queries: 20 for fallback testing

## Deployment Architecture

### Local Development

```yaml
# docker-compose.yml
services:
  api:
    build: ./Backend
    ports: ["8000:8000"]
    env_file: .env
    depends_on: [qdrant, postgres]

  qdrant:
    image: qdrant/qdrant:latest
    ports: ["6333:6333"]
    volumes: [qdrant_data:/qdrant/storage]

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ragchat
      POSTGRES_USER: dev
      POSTGRES_PASSWORD: dev
    ports: ["5432:5432"]
```

### Production

| Component | Service | Configuration |
|-----------|---------|---------------|
| FastAPI | Railway/Render | 2+ workers, auto-scale |
| Qdrant | Qdrant Cloud | Managed, replicated |
| Postgres | Neon | Serverless, auto-scale |
| Docusaurus | GitHub Pages | Static hosting |

### Environment Variables

```bash
# Required
OPENAI_API_KEY=sk-...
COHERE_API_KEY=...
QDRANT_URL=https://xxx.qdrant.io
QDRANT_API_KEY=...
DATABASE_URL=postgres://...

# Optional
OPENROUTER_API_KEY=sk-or-...  # Fallback LLM
LOG_LEVEL=INFO
CORS_ORIGINS=https://your-site.github.io
```

## Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| Query latency (p50) | <2s | End-to-end |
| Query latency (p95) | <3s | End-to-end |
| Vector search | <100ms | Qdrant query |
| First token | <500ms | Streaming start |
| Concurrent users | 100 | Without degradation |
| Availability | 99% | Uptime monitoring |
| Ingestion speed | 100 chunks/min | Batch processing |

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| OpenAI rate limits | OpenRouter fallback + request queue |
| High latency | Streaming responses, caching |
| Data inconsistency | Transactional ingestion, content hashing |
| Prompt injection | System prompt hardening, input sanitization |

## Dependencies

### Python Packages

```txt
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
openai>=1.12.0
qdrant-client>=1.7.0
asyncpg>=0.29.0
pydantic>=2.6.0
pydantic-settings>=2.1.0
python-dotenv>=1.0.0
httpx>=0.26.0
tiktoken>=0.6.0
alembic>=1.13.0
structlog>=24.1.0
```

### External Services

| Service | Purpose | Fallback |
|---------|---------|----------|
| OpenAI API | LLM generation | OpenRouter |
| Cohere API | Embeddings | None |
| Qdrant Cloud | Vector storage | Self-hosted |
| Neon Postgres | Metadata | Standard Postgres |

## Next Steps

1. Run `/sp.tasks` to generate implementation task list
2. Set up development environment per [quickstart.md](./quickstart.md)
3. Implement Phase 1: Setup (project structure, dependencies)
4. Implement Phase 2: Foundational (database connections, base models)
5. Implement User Stories in priority order (P1 â†’ P2 â†’ P3 â†’ P4)

---

ðŸ“‹ **Architectural decision detected**: Technology stack selection (FastAPI + Qdrant + Neon + OpenAI SDK) represents a significant architectural choice.
Document reasoning and tradeoffs? Run `/sp.adr "RAG Chatbot Technology Stack Selection"`
